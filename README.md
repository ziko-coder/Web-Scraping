# Web-Scraping Project: Disney Movie Dataset
## Overview
This project aims to create a comprehensive dataset of Disney movies by leveraging web scraping techniques on Wikipedia. By using various libraries, including BeautifulSoup, regular expressions, and the OMDb API, we extract valuable information such as movie titles, release dates, budgets, and additional data. The final dataset is saved in CSV format for easy accessibility and analysis.
## Features
* Web scraping with BeautifulSoup: The project utilizes the BeautifulSoup library to extract relevant information from Wikipedia pages.
* Data Cleaning: The scraped data undergoes a cleaning process to ensure consistency and accuracy.
* Pattern matching with regular expressions: Regular expressions (Re Library) are employed for effective pattern matching and extraction of specific data elements.
* Date and Budget Formatting: The extracted dates and budget figures are properly formatted for better analysis and visualization.
* Data Serialization: The project employs the Pickle library to save and load the processed data efficiently.
* API Integration: The OMDb API is utilized to fetch additional data on Disney movies, enhancing the dataset's comprehensiveness.
* Export to CSV: The final dataset is saved in the CSV format, enabling easy integration with various data analysis tools and platforms.
## Getting Started
To get started with this project, follow the steps below:
1. Clone the repository: git clone https://github.com/your-username/web-scraping-disney.git
2. Install the required dependencies: pip install -r requirements.txt
3. Run the main script: python scrape.py
4. Explore the generated dataset: data/disney_movies.csv
## Dependencies
* Python 3.7+
* BeautifulSoup
* Re Library
* Pandas
Make sure to install these dependencies using pip before running the project.
## Dataset
The dataset generated by this project contains a comprehensive collection of Disney movies, including relevant information such as title, release date, budget, and additional details. The dataset is saved in CSV format, enabling easy integration with popular data analysis tools and frameworks.
## Contribution
Contributions are welcome to enhance the project's functionality, efficiency, and data coverage. If you'd like to contribute, please follow these guidelines:
* Fork the repository.
* Create a new branch for your feature or bug fix.
* Commit your changes with descriptive commit messages.
* Push your changes to your forked repository.
* Open a pull request, detailing your changes and their benefits.
## Licence
This project is licensed under the MIT License. Feel free to use, modify, and distribute it as per the terms of the license.
## Acknowledgements
I would like to acknowledge the following resources and libraries that made this project possible:
* Keith Galli: https://youtu.be/Ewgy-G9cmbg
* BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
* OMDb API: https://www.omdbapi.com/
* Python Regular Expressions: https://docs.python.org/3/library/re.html

# Happy web scraping and data exploration!
